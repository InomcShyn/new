#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test script for Facebook Groups Comment Scraper - Mobile Facebook Fix
"""

import sys
import os

# Add current directory to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from fb_groups_comment_scraper import FacebookGroupsScraper

def test_mobile_fix():
    """Test the scraper with mobile Facebook fix"""
    
    print("ğŸ§ª Testing Facebook Groups Comment Scraper - Mobile Facebook Fix")
    print("=" * 70)
    
    # Test URL (replace with your actual Groups post URL)
    test_url = "https://www.facebook.com/groups/zui.vn/posts/24265734123027065"
    
    # Cookie string (you need to provide this)
    cookie_str = input("Paste your Facebook cookie string: ").strip()
    
    if not cookie_str:
        print("âŒ No cookie provided. Exiting.")
        return
    
    print("\nğŸš€ Starting test with mobile Facebook fix...")
    
    try:
        # Initialize scraper (headless=False for debugging)
        print("ğŸŒ Initializing scraper...")
        scraper = FacebookGroupsScraper(cookie_str, headless=False)
        
        # Load post (this will automatically try to switch to "All comments")
        print(f"ğŸ“„ Loading post: {test_url}")
        success = scraper.load_post(test_url)
        
        if not success:
            print("âŒ Failed to load post")
            return
        
        print("âœ… Post loaded successfully!")
        print("ğŸ”„ The scraper should have automatically switched to 'All comments' view")
        
        # Wait a bit for comments to load
        print("â³ Waiting for comments to load...")
        import time
        time.sleep(5)
        
        # Extract comments
        print("\nğŸ” Extracting comments from mobile Facebook...")
        comments = scraper.extract_groups_comments()
        
        print(f"\nğŸ“Š Results: {len(comments)} comments found")
        
        if comments:
            # Display results
            print("\n" + "="*50)
            print("ğŸ“‹ EXTRACTED COMMENTS:")
            print("="*50)
            
            for i, comment in enumerate(comments[:10]):  # Show first 10
                print(f"\n--- Comment {i+1} ---")
                print(f"Name: {comment['Name']}")
                print(f"UID: {comment['UID']}")
                print(f"Profile: {comment['ProfileLink']}")
                print(f"Comment Link: {comment['CommentLink']}")
                print(f"Type: {comment['Type']}")
                print(f"Layout: {comment['Layout']}")
            
            if len(comments) > 10:
                print(f"\n... and {len(comments) - 10} more comments")
            
            # Statistics
            main_count = len([c for c in comments if c['Type'] == 'Comment'])
            reply_count = len([c for c in comments if c['Type'] == 'Reply'])
            unique_users = len(set(c['Name'] for c in comments if c['Name'] != 'Unknown'))
            profile_links = len([c for c in comments if c['ProfileLink']])
            comment_links = len([c for c in comments if c['CommentLink']])
            uid_count = len([c for c in comments if c['UID'] != 'Unknown'])
            
            print(f"\nğŸ“ˆ STATISTICS:")
            print(f"Main Comments: {main_count}")
            print(f"Replies: {reply_count}")
            print(f"Unique Users: {unique_users}")
            print(f"Profile Links: {profile_links}")
            print(f"Comment Links: {comment_links}")
            print(f"UIDs Found: {uid_count}")
            
        else:
            print("âš ï¸ No comments found. This might indicate:")
            print("   - The post doesn't have comments")
            print("   - Access permission issues")
            print("   - The mobile selectors need further adjustment")
            print("   - Check the debug HTML file for more details")
            
            # Try to analyze the page structure
            print("\nğŸ” Analyzing page structure...")
            try:
                page_source = scraper.driver.page_source
                
                # Look for specific patterns from your div example
                if 'class="m"' in page_source:
                    print("âœ… Found 'class=\"m\"' elements in page")
                else:
                    print("âŒ No 'class=\"m\"' elements found")
                    
                if 'class="f20"' in page_source:
                    print("âœ… Found 'class=\"f20\"' elements in page")
                else:
                    print("âŒ No 'class=\"f20\"' elements found")
                    
                if 'data-action-id' in page_source:
                    print("âœ… Found 'data-action-id' elements in page")
                else:
                    print("âŒ No 'data-action-id' elements found")
                    
                if 'ÄÄƒng Trung' in page_source:
                    print("âœ… Found 'ÄÄƒng Trung' text in page")
                else:
                    print("âŒ No 'ÄÄƒng Trung' text found")
                    
            except Exception as e:
                print(f"âš ï¸ Error analyzing page structure: {e}")
        
        # Clean up
        scraper.close()
        
    except Exception as e:
        print(f"âŒ Error during testing: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    test_mobile_fix()